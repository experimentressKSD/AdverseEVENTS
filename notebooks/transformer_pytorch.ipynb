{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Attention based model for sepsis.\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, balanced_accuracy_score)\n",
    "# from test_tube import HyperOptArgumentParser\n",
    "\n",
    "# import src.torch.datasets\n",
    "# from src.torch.datasets import CombinedDataset\n",
    "# from src.evaluation import physionet2019_utility\n",
    "# from src.torch.torch_utils import (\n",
    "#     variable_length_collate, ComposeTransformations, LabelPropagation)\n",
    "# from src.torch.cli_utils import str2bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq, offset=0):\n",
    "    \"\"\"For masking out the subsequent info.\"\"\"\n",
    "    sz_b, len_s, n_features = seq.size()\n",
    "    subsequent_mask = torch.triu(\n",
    "        torch.ones(\n",
    "            (len_s+offset, len_s+offset), device=seq.device, dtype=bool),\n",
    "        diagonal=1\n",
    "    )\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def length_to_mask(length, max_len=None, dtype=None, offset=0):\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or (length.max().item() + offset)\n",
    "    mask = (\n",
    "        torch.arange(max_len, device=length.device, dtype=length.dtype) \\\n",
    "        .expand(len(length), max_len)\n",
    "        >= (length.unsqueeze(1) + offset)\n",
    "    )\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask\n",
    "\n",
    "\n",
    "class MaskedLayerNorm(nn.LayerNorm):\n",
    "    def forward(self, x):\n",
    "        # Compute cumulative summary statics along time axis\n",
    "        N = torch.arange(\n",
    "            start=1., end=x.shape[1]+1, device=x.device)[None, :, None]\n",
    "        mean_x = torch.cumsum(x, 1) / N\n",
    "        std_x = torch.sqrt(torch.cumsum((x - mean_x) ** 2, 1) / N + self.eps)\n",
    "\n",
    "        return ((x - mean_x) / std_x) * self.weight + self.bias\n",
    "\n",
    "\n",
    "class ReZero(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resweight = nn.Parameter(torch.Tensor([0.]))\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return x1 + self.resweight * x2\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"TransformerEncoderLayer is made up of self-attn and feedforward network.\n",
    "    This standard encoder layer is based on the paper \"Attention Is All You\n",
    "    Need\".  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\n",
    "    Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention\n",
    "    is all you need. In Advances in Neural Information Processing Systems,\n",
    "    pages 6000-6010. Users may modify or implement in a different way during\n",
    "    application.\n",
    "\n",
    "    This class is adapted from the pytorch source code.\n",
    "\n",
    "    Args:\n",
    "        d_model: the number of expected features in the input (required).\n",
    "        nhead: the number of heads in the multiheadattention models (required).\n",
    "        dim_feedforward: the dimension of the feedforward network model\n",
    "            (default=2048).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        norm: Normalization to apply, one of 'layer' or 'rezero'.\n",
    "\n",
    "    Examples::\n",
    "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        >>> src = torch.rand(10, 32, 512)\n",
    "        >>> out = encoder_layer(src)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n",
    "                 norm='layer'):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        if norm == 'layer':\n",
    "            def get_residual():\n",
    "                def residual(x1, x2):\n",
    "                    return x1 + x2\n",
    "                return residual\n",
    "\n",
    "            def get_norm():\n",
    "                return nn.LayerNorm(d_model)\n",
    "        elif norm == 'rezero':\n",
    "            def get_residual():\n",
    "                return ReZero()\n",
    "\n",
    "            def get_norm():\n",
    "                return nn.Identity()\n",
    "        else:\n",
    "            raise ValueError('Invalid normalization: {}'.format(norm))\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = get_norm()\n",
    "        self.norm2 = get_norm()\n",
    "        self.residual1 = get_residual()\n",
    "        self.residual2 = get_residual()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            src: the sequence to the encoder layer (required).\n",
    "            src_mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        src2 = self.self_attn(\n",
    "            src, src, src,\n",
    "            attn_mask=src_mask,\n",
    "            key_padding_mask=src_key_padding_mask\n",
    "        )[0]\n",
    "        src = self.residual1(src, self.dropout1(src2))\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = self.residual2(src, self.dropout2(src2))\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "\n",
    "class AttentionModel(pl.LightningModule):\n",
    "    \"\"\"Sequence to sequence model based on MultiHeadAttention.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, n_layers, n_heads, dropout, norm, indicators=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"AttentionModel.\n",
    "\n",
    "        Args:\n",
    "            d_model: Dimensionality of the model\n",
    "            n_layers: Number of MultiHeadAttention layers\n",
    "            n_heads: Number of attention heads\n",
    "            indicators: flag if missingness indicators should be applied\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        ff_dim = 4*d_model # dimensionality of ff layers: hard-coded default\n",
    "        #self.to_observation_tuples = to_observation_tuples if indicators else to_observation_tuples_without_indicators \n",
    "        self.save_hyperparameters()\n",
    "        d_in = 7\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(d_in, d_model)]\n",
    "            + [\n",
    "                TransformerEncoderLayer(\n",
    "                    d_model, n_heads, ff_dim, dropout, norm=norm)\n",
    "                for n in range(n_layers)\n",
    "            ]\n",
    "            + [nn.Linear(d_model, 1)]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def transforms(self):\n",
    "        parent_transforms = super().transforms\n",
    "        parent_transforms.extend([\n",
    "            PositionalEncoding(1, 500, 10),  # apply positional encoding\n",
    "            self.to_observation_tuples            # mask nan with zero add indicator\n",
    "        ])\n",
    "        return parent_transforms\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"Apply attention model to input x.\"\"\"\n",
    "        offset = 0\n",
    "        # Invert mask as multi head attention ignores values which are true\n",
    "        mask = length_to_mask(lengths, offset=offset, max_len=x.shape[1])\n",
    "        future_mask = get_subsequent_mask(x, offset=offset)\n",
    "        x = self.layers[0](x)\n",
    "\n",
    "        x = x.permute(1, 0, 2)\n",
    "        for layer in self.layers[1:]:\n",
    "            if isinstance(layer, TransformerEncoderLayer):\n",
    "                x = layer(\n",
    "                    x, src_key_padding_mask=mask, src_mask=future_mask)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # Remove first element if statics are present\n",
    "        x = x[:, offset:, :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AttentionModel                           [32, 336, 1]              --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Linear: 2-1                       [32, 336, 128]            1,024\n",
       "│    └─TransformerEncoderLayer: 2-2      [336, 32, 128]            --\n",
       "│    │    └─MultiheadAttention: 3-1      [336, 32, 128]            66,048\n",
       "│    │    └─Dropout: 3-2                 [336, 32, 128]            --\n",
       "│    │    └─ReZero: 3-3                  [336, 32, 128]            1\n",
       "│    │    └─Identity: 3-4                [336, 32, 128]            --\n",
       "│    │    └─Linear: 3-5                  [336, 32, 512]            66,048\n",
       "│    │    └─Dropout: 3-6                 [336, 32, 512]            --\n",
       "│    │    └─Linear: 3-7                  [336, 32, 128]            65,664\n",
       "│    │    └─Dropout: 3-8                 [336, 32, 128]            --\n",
       "│    │    └─ReZero: 3-9                  [336, 32, 128]            1\n",
       "│    │    └─Identity: 3-10               [336, 32, 128]            --\n",
       "│    └─Linear: 2-3                       [336, 32, 1]              129\n",
       "==========================================================================================\n",
       "Total params: 198,915\n",
       "Trainable params: 198,915\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 44.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.30\n",
       "Forward/backward pass size (MB): 88.17\n",
       "Params size (MB): 0.53\n",
       "Estimated Total Size (MB): 89.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AttentionModel(d_model=128, n_layers=1, n_heads=8, dropout=0.1, norm='rezero')\n",
    "\n",
    "\n",
    "# Create some dummy data for x and lengths\n",
    "x = torch.rand(32, 336, 7)\n",
    "lengths = torch.randint(24, 336, (32,))\n",
    "\n",
    "# Call the model\n",
    "output = model(x, lengths)\n",
    "\n",
    "\n",
    "summary(model, input_data= [x, lengths],)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 336, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 336, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.layers\n",
    "from keras_nlp.layers import PositionEmbedding\n",
    "import numpy as np\n",
    "\n",
    "input = np.zeros((32, 336, 7))\n",
    "\n",
    "layer = PositionEmbedding(336)\n",
    "layer(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 336, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.layers\n",
    "from keras_nlp.layers import SinePositionEncoding\n",
    "import numpy as np\n",
    "\n",
    "input = np.zeros((32, 336, 7))\n",
    "\n",
    "layer = SinePositionEncoding()\n",
    "layer(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_bibtex_from_doi(doi):\n",
    "    url = f\"https://doi.org/{doi}\"\n",
    "    headers = {\"Accept\": \"application/x-bibtex\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @article{Veldhuis_2022, title={Artificial Intelligence for the Prediction of In-Hospital Clinical Deterioration: A Systematic Review}, volume={4}, ISSN={2639-8028}, url={http://dx.doi.org/10.1097/CCE.0000000000000744}, DOI={10.1097/cce.0000000000000744}, number={9}, journal={Critical Care Explorations}, publisher={Ovid Technologies (Wolters Kluwer Health)}, author={Veldhuis, Lars I. and Woittiez, Nicky J. C. and Nanayakkara, Prabath W. B. and Ludikhuize, Jeroen}, year={2022}, month=aug, pages={e0744} }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doi = \"10.1097/CCE.0000000000000744\"\n",
    "bibtex = generate_bibtex_from_doi(doi)\n",
    "print(bibtex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 10:04:55.349439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-15 10:04:55.349515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-15 10:04:55.401621: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-15 10:04:55.509502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 10:04:56.658721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, Bidirectional, GRU, Embedding, TimeDistributed, Concatenate, MultiHeadAttention\n",
    "from tcn import TCN, tcn_full_summary\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras_nlp.layers import PositionEmbedding, TransformerEncoder, SinePositionEncoding\n",
    "from tensorflow import linalg, ones, math, cast, float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 10:05:44.347323: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.575152: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.575349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.576575: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.576732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.576847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.781113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.781260: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.781354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-15 10:05:44.781714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 336, 7)]             0         []                            \n",
      "                                                                                                  \n",
      " masking (Masking)           (None, 336, 7)               0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLam  (None, 336, 7)               0         ['input_1[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 336, 128)             1024      ['masking[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)        (None, 336, 7)               0         ['tf.math.not_equal[0][0]']   \n",
      "                                                                                                  \n",
      " position_embedding_1 (Posi  (None, 336, 128)             43008     ['time_distributed[0][0]']    \n",
      " tionEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 336)                  0         ['tf.cast[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " transformer_encoder (Trans  (None, 336, 128)             99584     ['position_embedding_1[0][0]',\n",
      " formerEncoder)                                                      'tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 336, 1)               129       ['transformer_encoder[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143745 (561.50 KB)\n",
      "Trainable params: 143745 (561.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_padding_mask(input):\n",
    "    # Create mask which marks the 100000.0 padding values in the input by a 1\n",
    "    mask = tf.math.not_equal(input, 100000.0) # want 100000.0 to produce 0, aka no attention\n",
    "    mask = tf.cast(mask, tf.bool)\n",
    "    mask = mask[:, :, 0]\n",
    "    return mask\n",
    " \n",
    "def create_lookahead_mask(input):\n",
    "    # Mask out future entries by marking them with a 1.0\n",
    "    mask = 1 - linalg.band_part(ones((input.shape[1], input.shape[1])), -1, 0)\n",
    "    mask = tf.repeat(tf.expand_dims(mask, 0), input.shape[0], axis=0)\n",
    " \n",
    "    return mask\n",
    "    \n",
    "\n",
    "\n",
    "input_shape = (336, 7)\n",
    "intermediate_dim = 128\n",
    "num_heads=8\n",
    "num_transformer_layers=1\n",
    "\n",
    "position_embedding = PositionEmbedding(336)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "mask_layer = keras.layers.Masking(mask_value=100000.0)(inputs)\n",
    "\n",
    "\n",
    "dense_in = TimeDistributed(Dense(128))(mask_layer)\n",
    "\n",
    "x = position_embedding(dense_in)\n",
    "\n",
    "#x=mask_layer\n",
    "\n",
    "padding_mask = create_padding_mask(inputs)\n",
    "#lookahead_mask = create_lookahead_mask(inputs)\n",
    "\n",
    "transformer_block = TransformerEncoder(\n",
    "    num_heads=num_heads,\n",
    "    intermediate_dim=intermediate_dim,\n",
    "    dropout=0.1,\n",
    ")\n",
    "x = transformer_block(x, padding_mask=padding_mask)\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 12:46:31.985102: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.010633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.010777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.012101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.012223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.012305: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.182941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.183130: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.183255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-17 12:46:32.183341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1431 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30), dtype=bool, numpy=\n",
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import linalg, ones, math, cast, float32\n",
    "import numpy as np\n",
    "\n",
    "def create_padding_mask(input):\n",
    "    # Create mask which marks the 100000.0 padding values in the input by a 1\n",
    "    mask = tf.math.equal(input, 100000.0) # want 100000.0 to produce 0, aka no attention\n",
    "    mask = tf.cast(mask, tf.bool)\n",
    "    mask = mask[:, :, 0]\n",
    "    return mask\n",
    "\n",
    "arr = np.zeros((1, 30, 7))\n",
    "arr[:, 20:, :] = 100000.0\n",
    "create_padding_mask(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30, 30), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_lookahead_mask(input):\n",
    "    # Mask out future entries by marking them with a 1.0\n",
    "    mask = linalg.band_part(ones((input.shape[1], input.shape[1])), -1, 0)\n",
    "    mask = tf.repeat(tf.expand_dims(mask, 0), input.shape[0], axis=0)\n",
    " \n",
    "    return mask\n",
    "\n",
    "create_lookahead_mask(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
