{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths, defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = '/datasets/amelatur/mimic_m1pz92hj/'\n",
    "ids_file = pd.read_csv( main_folder_path + '0labels.txt')\n",
    "patient_ids = ids_file['id']\n",
    "\n",
    "vitals_folder_path = '/datasets/amelatur/mimic_kih7jlb3/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPI FAILURE\n",
    "\n",
    "sampling_rate_minutes = 30\n",
    "steps_per_hour = 60//sampling_rate_minutes\n",
    "\n",
    "ffill_p_f_hours = 2 * steps_per_hour\n",
    "pao2_normal = 80.0\n",
    "fio2_normal = 21.0\n",
    "\n",
    "p_f_ratio_threshold = 300\n",
    "window_ratio = 2/3\n",
    "window_length = 2 * steps_per_hour\n",
    "\n",
    "peep_interpolate_limit = 4 * steps_per_hour\n",
    "\n",
    "# EXTRA STUFF\n",
    "paco2_normal = 40\n",
    "paco2_threshold = 45\n",
    "ph_normal = 7.4\n",
    "ph_threshold = 7.35\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIRC FAILURE\n",
    "sampling_rate_minutes = 30\n",
    "steps_per_hour = 60//sampling_rate_minutes\n",
    "\n",
    "ffill_lactate_hours = 7 * steps_per_hour\n",
    "ffill_drugs_hours = 1 * steps_per_hour\n",
    "ffill_map_hours = 5 * steps_per_hour\n",
    "\n",
    "lactate_normal_value = 1.0\n",
    "map_normal_value = 90.0\n",
    "\n",
    "lactate_threshold = 2\n",
    "map_threshold = 65\n",
    "window_ratio = 2/3\n",
    "window_length = 2 * steps_per_hour\n",
    "\n",
    "# EXTRA STUFF\n",
    "hr_normal_value = 80\n",
    "hr_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random subset of patients \n",
    "number_patients = 200\n",
    "random_patient_ids = patient_ids.sample(n=number_patients, random_state=54)\n",
    "\n",
    "\n",
    "# select which diseases\n",
    "train_sepsis = False\n",
    "train_respi = True\n",
    "train_circ = False\n",
    "train_kidney = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESPIRATORY FAILURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_respi_fail (patient_id):\n",
    "\n",
    "    labs_file = pd.read_csv(main_folder_path + str(patient_id) + '_all_vals.csv', index_col=False)\n",
    "    labs_file['charttime'] = pd.to_datetime(labs_file['charttime'])\n",
    "    labs_file = labs_file.sort_values(by='charttime').set_index('charttime')\n",
    "\n",
    "    index_ = labs_file.index\n",
    "    n_steps = len(labs_file.index)\n",
    "\n",
    "    # annotate respiratory failure\n",
    "    respi_status = pd.Series(0, index=index_)\n",
    "\n",
    "    # P/F ratio\n",
    "    if not (labs_file['po2'].isna().all() or n_steps < 48):\n",
    "        exclusion_flag = 0\n",
    "        p_f_raw = labs_file[['po2', 'fio2']].reindex(index_, method='ffill', limit=ffill_p_f_hours) \n",
    "        p_f_raw = p_f_raw.interpolate(limit=ffill_p_f_hours)\n",
    "        p_f_raw['po2'] = p_f_raw['po2'].fillna(80.0) \n",
    "        p_f_raw['fio2'] = p_f_raw['fio2'].fillna(21.0)\n",
    "        ratio = 100 * p_f_raw['po2'] / p_f_raw['fio2'] \n",
    "\n",
    "        p_f_ratio =  pd.Series(ratio, index=index_)\n",
    "\n",
    "\n",
    "        # get ventilation status\n",
    "        vent_df = labs_file['vent_presence']\n",
    "\n",
    "        # peep \n",
    "        peep_interpolate_limit = 4 * steps_per_hour\n",
    "        peep = labs_file['peep'].reindex(index_, method='ffill', limit=peep_interpolate_limit).squeeze()\n",
    "\n",
    "        # take element-wise AND of peep and ventilation\n",
    "        vent_peep_status_dense = vent_df.squeeze() & peep.squeeze() > 4\n",
    "\n",
    "        peep[peep.isnull()] = 1\n",
    "        peep[~peep.isnull()] = 0\n",
    "        vent_peep_status_not_dense = (vent_df.squeeze()) & peep\n",
    "        \n",
    "        # annotate respiratory failure\n",
    "        respi_status = pd.DataFrame(0, index=index_, columns=['respi_failure']).squeeze()\n",
    "\n",
    "        n_steps = len(vent_peep_status_not_dense)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            start_window = i\n",
    "            end_window = min(n_steps, i + 2 * steps_per_hour)\n",
    "\n",
    "            vent_win = np.array(vent_peep_status_dense[start_window:end_window])\n",
    "            vent_win_not_dense = np.array(vent_peep_status_not_dense[start_window:end_window])\n",
    "            p_f_win = np.array(p_f_ratio[start_window:end_window])\n",
    "            \n",
    "            no_vent_cond = np.sum((p_f_win < 300) & (vent_win == False)) >= 1/2 * len(vent_win)\n",
    "            vent_cond_not_dense = np.sum((p_f_win < 300)& (vent_win_not_dense)) >= 1/2 * len(vent_win)\n",
    "            vent_cond_dense = np.sum((p_f_win) < 300 & (vent_win)) >= 1/2 * len(vent_win)\n",
    "\n",
    "            #vent_cond = np.sum((vent_win)) >= 2/3 * len(vent_win)\n",
    "\n",
    "            final = no_vent_cond + vent_cond_not_dense + vent_cond_dense\n",
    "            if final: \n",
    "                respi_status.iloc[i] = 1\n",
    "    else:\n",
    "        exclusion_flag = 1\n",
    "\n",
    "    # now return time of event\n",
    "    threshold = 3\n",
    "    result_index = respi_status[respi_status.groupby((respi_status != respi_status.shift()).cumsum()[respi_status.eq(1)]).transform('count') > threshold]\n",
    "    if result_index.empty == False:\n",
    "        result_index = respi_status.index.get_loc(result_index.idxmax())\n",
    "    else:\n",
    "        result_index = None\n",
    "\n",
    "    # now return an array that is full of 1s 6H before the event, and 2H after the event, and 0s otherwise (clip the array 2H after event)\n",
    "    final_target_series = pd.Series(0, index=index_)\n",
    "    if result_index != None:\n",
    "        start_event = max(0, result_index - 6*2)\n",
    "        end_event = min(n_steps, result_index + 2*2)\n",
    "        final_target_series.iloc[start_event:end_event] = 1\n",
    "\n",
    "\n",
    "    # now get the vitals as inputs\n",
    "    vitals_file = pd.read_csv(vitals_folder_path + str(patient_id) + '_vitals.csv', index_col=False)\n",
    "    vitals_file['time'] = pd.to_datetime(vitals_file['time'])\n",
    "    vitals_file = vitals_file.set_index('time')\n",
    "    vitals = vitals_file.drop(['Unnamed: 0', 'id'], axis=1).resample('30T').mean() \n",
    "    vitals = vitals.ffill().bfill()\n",
    "    if vitals.isna().any().any():\n",
    "        exclusion_flag = 1\n",
    "\n",
    "\n",
    "    # now calculate the number of valid tensors that we can use\n",
    "    \n",
    "    nb_timesteps_per_tensor = 4*2 # 2 steps per hour, 4H total --> 8 timesteps per tensor\n",
    "    if result_index != None:\n",
    "        end_index_usable = math.ceil(end_event / nb_timesteps_per_tensor) * nb_timesteps_per_tensor\n",
    "        vitals = vitals[:end_index_usable]\n",
    "        final_target_series.iloc[end_event:end_index_usable] = 1\n",
    "        final_target_series = final_target_series[:end_index_usable]\n",
    "\n",
    "    \n",
    "\n",
    "    input_dataset = tf.keras.utils.timeseries_dataset_from_array(np.array(vitals), None, sequence_length = 4*2)\n",
    "    target_dataset = tf.keras.utils.timeseries_dataset_from_array(np.array(final_target_series), None, sequence_length = 4*2)\n",
    "\n",
    "    return exclusion_flag, input_dataset, target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_flag, input_dataset, target_dataset = get_respi_fail(random_patient_ids.iloc[0])\n",
    "# for batch in input_dataset:\n",
    "#   inputs = batch\n",
    "#   print (inputs.shape)\n",
    "# print(\"______\")\n",
    "# for batch in target_dataset:\n",
    "#   target = batch\n",
    "#   print ((target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIRCULATORY FAILURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circ_fail(patient_id):\n",
    "\n",
    "    #vitals_file = pd.read_csv(main_folder_path + str(patient_id) + '_vitals.csv', index_col=False)\n",
    "    labs_file = pd.read_csv(main_folder_path + str(patient_id) + '_all_vals.csv', index_col=False)\n",
    "\n",
    "    #vitals_file['time'] = pd.to_datetime(vitals_file['time'])\n",
    "    labs_file['charttime'] = pd.to_datetime(labs_file['charttime'])\n",
    "\n",
    "    #vitals_file = vitals_file.set_index('time')\n",
    "    labs_file = labs_file.set_index('charttime')\n",
    "    index_ = labs_file.index\n",
    "    n_steps = len(labs_file.index)\n",
    "    circ_status = pd.Series(0, index=index_, name=\"circ\")\n",
    "\n",
    "    # if not (labs_file['mbp'].isna().all() or labs_file['uo_rt_6hr'].isna().all() or labs_file['heart_rate'].isna().all() or labs_file['lactate'].isna().all() or n_steps < 48):\n",
    "    if not (n_steps < 48 or labs_file['mbp'].isna().all() or labs_file['lactate'].isna().all()):\n",
    "        excl_flag = 0\n",
    "        lactate_final = labs_file['lactate']\n",
    "        lactate_final = lactate_final.ffill(limit=ffill_lactate_hours)\n",
    "        lactate_final.loc[:lactate_final.first_valid_index()] = lactate_normal_value\n",
    "        lactate_final = lactate_final.interpolate(limit=ffill_lactate_hours)\n",
    "        lactate_final = lactate_final.fillna(lactate_normal_value)\n",
    "\n",
    "        drug_df = labs_file['drug_presence'] # to series\n",
    "\n",
    "        map_values = labs_file['mbp']\n",
    "        map_values = map_values.ffill(limit=ffill_map_hours)\n",
    "        map_values.loc[:map_values.first_valid_index()] = map_normal_value\n",
    "        map_values = map_values.interpolate(limit=ffill_map_hours)\n",
    "        map_values = map_values.fillna(map_normal_value)\n",
    "\n",
    "        # Now calculate circ failure on imputed dataframes\n",
    "        # final circ_status column filled with 0s\n",
    "        event_window_length = window_length\n",
    "        half_length = event_window_length//2\n",
    "\n",
    "        # EXTRA STUFF: HR --> impute in the same manner as all values above (MAP, lactate)\n",
    "        hr = labs_file['heart_rate']\n",
    "        hr = hr.ffill(limit=ffill_map_hours)\n",
    "        hr.loc[:hr.first_valid_index()] = hr_normal_value\n",
    "        hr = hr.interpolate(limit=ffill_map_hours)\n",
    "        hr = hr.fillna(hr_normal_value)\n",
    "\n",
    "        # urine output\n",
    "        uo = labs_file['uo_rt_6hr']\n",
    "        uo = uo.ffill()\n",
    "        uo = uo.fillna(1.5)\n",
    "\n",
    "        for idx in range(n_steps):\n",
    "\n",
    "            start_idx = max(0, idx - half_length)\n",
    "            end_idx = min(n_steps, idx + half_length)\n",
    "\n",
    "            map_wind = np.array(map_values[start_idx:end_idx+1])\n",
    "            lactate_wind = np.array(lactate_final[start_idx:end_idx+1])\n",
    "            drugs_wind = np.array(drug_df[start_idx:end_idx+1])\n",
    "            hr_wind = np.array(hr[start_idx:end_idx+1])\n",
    "            uo_wind = np.array(uo[start_idx:end_idx+1])\n",
    "\n",
    "            pharma_cond = drugs_wind > 0\n",
    "            map_cond = map_wind < 70\n",
    "            hr_cond = hr_wind > hr_threshold\n",
    "            uo_cond = uo_wind < 0.5\n",
    "\n",
    "            map_full_cond = (map_cond | pharma_cond)\n",
    "            #map_full_cond = map_cond\n",
    "            lact_crit_arr = (lactate_wind > 1.5)\n",
    "            map_state = np.sum(map_full_cond) >= window_ratio * len(map_full_cond)\n",
    "            lac_state = np.sum(lact_crit_arr) >= window_ratio * len(map_full_cond)\n",
    "            uo_state = np.sum(uo_cond) >= window_ratio * len(map_full_cond)\n",
    "            hr_state = np.sum(hr_cond) >= 1/2 * len(map_full_cond)\n",
    "            secondary = lac_state or uo_state\n",
    "            if map_state and lac_state:\n",
    "            # if (map_state and lac_state):\n",
    "                circ_status.iloc[idx] = 1.0\n",
    "\n",
    "    else:\n",
    "        excl_flag = 1\n",
    "\n",
    "    # now return time of event\n",
    "    threshold = 3\n",
    "    result_index = circ_status[circ_status.groupby((circ_status != circ_status.shift()).cumsum()[circ_status.eq(1)]).transform('count') > threshold]\n",
    "    if result_index.empty == False:\n",
    "        result_index = circ_status.index.get_loc(result_index.idxmax())\n",
    "    else:\n",
    "        result_index = None\n",
    "    \n",
    "    return circ_status, excl_flag, result_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACUTE KIDNEY INJURY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kidney_fail(patient_id):\n",
    "    #vitals_file = pd.read_csv(main_folder_path + str(patient_id) + '_vitals.csv', index_col=False)\n",
    "    labs_file = pd.read_csv(main_folder_path + str(patient_id) + '_all_vals.csv', index_col=False)\n",
    "\n",
    "    #vitals_file['time'] = pd.to_datetime(vitals_file['time'])\n",
    "    labs_file['charttime'] = pd.to_datetime(labs_file['charttime'])\n",
    "\n",
    "    #vitals_file = vitals_file.set_index('time')\n",
    "    labs_file = labs_file.set_index('charttime')\n",
    "    n_steps = len(labs_file.index)\n",
    "    if (n_steps < 48):\n",
    "        excl_flag = 1\n",
    "    else:\n",
    "        excl_flag = 0\n",
    "\n",
    "    kidney_status = pd.Series(0, index=labs_file.index, name=\"kidney\")\n",
    "    target_value = 2.0\n",
    "    earliest_index = labs_file['aki_stage'].squeeze().eq(target_value)\n",
    "    if earliest_index.any() == True:\n",
    "        earliest_index = labs_file.index.get_loc(earliest_index.idxmax())\n",
    "        kidney_status[earliest_index:] = 1\n",
    "    else:\n",
    "        earliest_index = None\n",
    "\n",
    "    return labs_file['aki_stage'], excl_flag, earliest_index, kidney_status\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charttime\n",
      "2180-09-20 16:00:00    0.0\n",
      "2180-09-20 16:30:00    NaN\n",
      "2180-09-20 17:00:00    NaN\n",
      "2180-09-20 17:30:00    NaN\n",
      "2180-09-20 18:00:00    0.0\n",
      "2180-09-20 18:30:00    NaN\n",
      "2180-09-20 19:00:00    0.0\n",
      "2180-09-20 19:30:00    0.0\n",
      "2180-09-20 20:00:00    0.0\n",
      "2180-09-20 20:30:00    NaN\n",
      "2180-09-20 21:00:00    0.0\n",
      "2180-09-20 21:30:00    NaN\n",
      "2180-09-20 22:00:00    NaN\n",
      "2180-09-20 22:30:00    NaN\n",
      "2180-09-20 23:00:00    NaN\n",
      "2180-09-20 23:30:00    NaN\n",
      "2180-09-21 00:00:00    2.0\n",
      "2180-09-21 00:30:00    NaN\n",
      "2180-09-21 01:00:00    1.0\n",
      "2180-09-21 01:30:00    NaN\n",
      "Name: aki_stage, dtype: float64 charttime\n",
      "2180-09-20 16:00:00    0\n",
      "2180-09-20 16:30:00    0\n",
      "2180-09-20 17:00:00    0\n",
      "2180-09-20 17:30:00    0\n",
      "2180-09-20 18:00:00    0\n",
      "2180-09-20 18:30:00    0\n",
      "2180-09-20 19:00:00    0\n",
      "2180-09-20 19:30:00    0\n",
      "2180-09-20 20:00:00    0\n",
      "2180-09-20 20:30:00    0\n",
      "2180-09-20 21:00:00    0\n",
      "2180-09-20 21:30:00    0\n",
      "2180-09-20 22:00:00    0\n",
      "2180-09-20 22:30:00    0\n",
      "2180-09-20 23:00:00    0\n",
      "2180-09-20 23:30:00    0\n",
      "2180-09-21 00:00:00    1\n",
      "2180-09-21 00:30:00    1\n",
      "2180-09-21 01:00:00    1\n",
      "2180-09-21 01:30:00    1\n",
      "Name: kidney, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "aki, excl_flag, earliest_index, kidney_status = get_kidney_fail(random_patient_ids.iloc[150])\n",
    "print(aki[10:30], kidney_status[10:30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sepsis(patient_id):\n",
    "\n",
    "    detected_sepsis = ids_file[ids_file['id'] == patient_id]['sepsis'].values[0]\n",
    "    \n",
    "    labs_file = pd.read_csv(main_folder_path + str(patient_id) + '_all_vals.csv', index_col=False)\n",
    "    labs_file['charttime'] = pd.to_datetime(labs_file['charttime'])\n",
    "    labs_file = labs_file.set_index('charttime')\n",
    "    n_steps = len(labs_file.index)\n",
    "    excl_flag = 0\n",
    "    sepsis_index = None\n",
    "    sepsis_time = None\n",
    "    if (n_steps < 48):\n",
    "        excl_flag = 1\n",
    "    if detected_sepsis == True:\n",
    "        sepsis_time = pd.to_datetime(ids_file[ids_file['id'] == patient_id]['sepsis_time'].values[0])\n",
    "        first_vital = min(labs_file.index)\n",
    "        if (sepsis_time < first_vital):\n",
    "            excl_flag = 1\n",
    "        sepsis_index = labs_file.index.get_loc(sepsis_time) \n",
    "    \n",
    "    return detected_sepsis, excl_flag, sepsis_index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 15:20:58.439646: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n",
      "    return nest_util.flatten_up_to(\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1542, in flatten_up_to\n",
      "    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1571, in _tf_data_flatten_up_to\n",
      "    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1415, in _tf_data_assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: '_BatchDataset'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\n",
      "\n",
      "\n",
      "2024-01-17 15:20:58.440539: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None), dtype=tf.int64, name=None)>.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n",
      "    return nest_util.flatten_up_to(\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1542, in flatten_up_to\n",
      "    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1571, in _tf_data_flatten_up_to\n",
      "    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1415, in _tf_data_assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: '_BatchDataset'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None), dtype=tf.int64, name=None)>.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\nTraceback (most recent call last):\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1542, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1571, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1415, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: '_BatchDataset'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m data_loader \u001b[39m=\u001b[39m custom_data_loader(batch_size)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Example of using the data loader in a training loop\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Your training logic goes here\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInputs shape:\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTargets shape:\u001b[39m\u001b[39m\"\u001b[39m, targets\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    811\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    774\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    775\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    776\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    778\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3030\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\nTraceback (most recent call last):\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1542, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1571, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1415, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: '_BatchDataset'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/amelatur/.pyenv/versions/3.10.12/envs/my_proj/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32), but the yielded element was <_BatchDataset element_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None)>.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def data_generator():\n",
    "    # Your data generation logic goes here\n",
    "        exclusion_flag, input_dataset, target_dataset = get_respi_fail(pat_id)\n",
    "        if exclusion_flag == 0:\n",
    "            return input_dataset, target_dataset\n",
    "\n",
    "\n",
    "def custom_data_loader(batch_size):\n",
    "    # Create a dataset from the generator function\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        data_generator,\n",
    "        output_types=(tf.float32, tf.float32)\n",
    "    )\n",
    "\n",
    "    # Batch and prefetch the dataset\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Specify the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create the custom data loader\n",
    "data_loader = custom_data_loader(batch_size)\n",
    "\n",
    "# Example of using the data loader in a training loop\n",
    "for inputs, targets in data_loader:\n",
    "    # Your training logic goes here\n",
    "    print(\"Inputs shape:\", inputs.shape)\n",
    "    print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 09:45:28.111189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.562735: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.562991: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.590449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.590714: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.590800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.838503: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.839056: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.839462: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 09:45:28.839526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1037 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/tmp/ipykernel_1237951/3835551409.py:82: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  vitals_file['time'] = pd.to_datetime(vitals_file['time'])\n"
     ]
    }
   ],
   "source": [
    "list_inputs = []\n",
    "list_targets = []\n",
    "\n",
    "for idx, pat_id in random_patient_ids.items():\n",
    "    exclusion_flag, input_dataset, target_dataset = get_respi_fail(pat_id)\n",
    "    if exclusion_flag == 0:\n",
    "        for batch in input_dataset:\n",
    "            list_inputs.append(batch)\n",
    "        for batch in target_dataset:\n",
    "            list_targets.append(batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "exclusion_flag, input_dataset, target_dataset = get_respi_fail(random_patient_ids.iloc[150])\n",
    "\n",
    "for batch in input_dataset:\n",
    "    for tensor in batch:\n",
    "        print(type(np.array(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input_dataset = tf.concat(list_inputs, 0)\n",
    "final_target_dataset = tf.concat(list_targets, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 7)]               0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 6, 64)                1408      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 4, 128)               24704     ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 4, 128)               0         ['conv1d_1[0][0]',            \n",
      "                                                                     'conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['attention[0][0]']           \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   8256      ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 8)                    520       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34888 (136.28 KB)\n",
      "Trainable params: 34888 (136.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 15:50:10.755203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:10.943506: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:10.943644: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:10.944738: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:10.944849: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:10.944940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:11.000903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:11.001100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:11.001239: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-24 15:50:11.001336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7697 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow. layers import Input, Conv1D, GlobalAveragePooling1D, Dense, Attention\n",
    "\n",
    "\n",
    "# CONV1D WITH ATTENTION\n",
    "def create_conv1d_attention_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    attention = Attention()([x, x])\n",
    "    x = GlobalAveragePooling1D()(attention)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# CONV1D WITHOUT ATTENTION\n",
    "def create_conv1d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    attention = Attention()([x, x])\n",
    "    x = GlobalAveragePooling1D()(attention)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(input_shape[0], activation='sigmoid')(x)  # Sigmoid for binary classification\n",
    "\n",
    "    model = tf. Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (8, 7)\n",
    "\n",
    "model = create_conv1d(input_shape)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf. losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 48, 6)]           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 48, 64)            1216      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 48, 64)            256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 48, 64)            0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 48, 64)            12352     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 48, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 48, 64)            0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 48, 64)            12352     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 48, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 48, 64)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d_4  (None, 64)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 48)                3120      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29808 (116.44 KB)\n",
      "Trainable params: 29424 (114.94 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, GlobalAveragePooling1D, Dense, Attention, BatchNormalization, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "sampling_rate_mins = 5\n",
    "n_timesteps = 60//sampling_rate_mins\n",
    "window_length_hours = 4\n",
    "\n",
    "nb_features_vitals = 6 \n",
    "\n",
    "def create_conv1d(input_shape):\n",
    "    \n",
    "    input_layer =  Input(input_shape)\n",
    "\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "\n",
    "    conv2 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "\n",
    "    conv3 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "\n",
    "    gap = GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = Dense(input_shape[0], activation=\"sigmoid\")(gap)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "input_shape = (window_length_hours * n_timesteps, nb_features_vitals)\n",
    "\n",
    "model = create_conv1d(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 09:46:27.084051: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-18 09:46:27.323676: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-18 09:46:28.033563: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-18 09:46:28.793829: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd437bbd780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-18 09:46:28.793849: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2024-01-18 09:46:28.828001: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705567588.950806 1254904 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 8s 27ms/step - loss: 0.5058 - accuracy: 0.1435 - val_loss: 0.6237 - val_accuracy: 0.1493\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.3005 - accuracy: 0.1300 - val_loss: 0.6155 - val_accuracy: 0.0048\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2892 - accuracy: 0.0960 - val_loss: 0.5816 - val_accuracy: 0.4074\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2842 - accuracy: 0.1078 - val_loss: 0.5804 - val_accuracy: 0.0072\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.2816 - accuracy: 0.0928 - val_loss: 0.5959 - val_accuracy: 0.2115\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.2757 - accuracy: 0.1002 - val_loss: 0.6258 - val_accuracy: 0.0131\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2801 - accuracy: 0.0916 - val_loss: 0.5563 - val_accuracy: 0.0346\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2775 - accuracy: 0.0745 - val_loss: 0.5543 - val_accuracy: 0.0167\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2761 - accuracy: 0.0971 - val_loss: 0.5377 - val_accuracy: 0.1051\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2790 - accuracy: 0.0728 - val_loss: 0.5103 - val_accuracy: 0.0323\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2737 - accuracy: 0.1241 - val_loss: 0.5661 - val_accuracy: 0.1314\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2693 - accuracy: 0.0595 - val_loss: 0.5559 - val_accuracy: 0.0406\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2723 - accuracy: 0.1152 - val_loss: 0.5648 - val_accuracy: 0.0119\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2766 - accuracy: 0.1207 - val_loss: 0.5412 - val_accuracy: 0.0526\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2733 - accuracy: 0.0760 - val_loss: 0.5740 - val_accuracy: 0.0968\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.2718 - accuracy: 0.1055 - val_loss: 0.5259 - val_accuracy: 0.0323\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2659 - accuracy: 0.0878 - val_loss: 0.5330 - val_accuracy: 0.0358\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2685 - accuracy: 0.1108 - val_loss: 0.5843 - val_accuracy: 0.0108\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2687 - accuracy: 0.0667 - val_loss: 0.5924 - val_accuracy: 0.0072\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.0766 - val_loss: 0.5289 - val_accuracy: 0.0239\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2639 - accuracy: 0.1051 - val_loss: 0.5228 - val_accuracy: 0.0215\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2612 - accuracy: 0.0599 - val_loss: 0.6722 - val_accuracy: 0.0072\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2649 - accuracy: 0.0525 - val_loss: 0.5161 - val_accuracy: 0.0239\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2594 - accuracy: 0.0663 - val_loss: 0.5329 - val_accuracy: 0.0084\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2544 - accuracy: 0.0502 - val_loss: 0.5800 - val_accuracy: 0.0227\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2485 - accuracy: 0.0435 - val_loss: 0.5918 - val_accuracy: 0.0072\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2500 - accuracy: 0.0449 - val_loss: 0.5809 - val_accuracy: 0.0108\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2576 - accuracy: 0.0648 - val_loss: 0.5819 - val_accuracy: 0.0072\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2507 - accuracy: 0.0310 - val_loss: 0.6087 - val_accuracy: 0.0155\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2522 - accuracy: 0.0517 - val_loss: 0.5719 - val_accuracy: 0.0239\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2529 - accuracy: 0.0519 - val_loss: 0.5553 - val_accuracy: 0.0167\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2544 - accuracy: 0.0477 - val_loss: 0.5536 - val_accuracy: 0.0108\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2602 - accuracy: 0.0502 - val_loss: 0.5738 - val_accuracy: 0.0131\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2508 - accuracy: 0.0129 - val_loss: 0.5331 - val_accuracy: 0.0119\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2481 - accuracy: 0.0544 - val_loss: 0.5291 - val_accuracy: 0.0084\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2407 - accuracy: 0.0196 - val_loss: 0.6157 - val_accuracy: 0.0096\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2371 - accuracy: 0.0133 - val_loss: 0.5273 - val_accuracy: 0.0406\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2381 - accuracy: 0.0319 - val_loss: 0.6769 - val_accuracy: 0.0227\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2387 - accuracy: 0.0403 - val_loss: 0.5419 - val_accuracy: 0.0406\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2299 - accuracy: 0.0101 - val_loss: 0.5727 - val_accuracy: 0.0060\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2418 - accuracy: 0.0165 - val_loss: 0.5251 - val_accuracy: 0.0119\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2366 - accuracy: 0.0171 - val_loss: 0.5869 - val_accuracy: 0.0084\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2438 - accuracy: 0.0158 - val_loss: 0.6389 - val_accuracy: 0.0084\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2290 - accuracy: 0.0203 - val_loss: 0.5846 - val_accuracy: 0.1912\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2285 - accuracy: 0.0228 - val_loss: 0.5606 - val_accuracy: 0.0299\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2256 - accuracy: 0.0502 - val_loss: 0.5813 - val_accuracy: 0.0562\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2186 - accuracy: 0.0143 - val_loss: 0.6181 - val_accuracy: 0.0311\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2236 - accuracy: 0.0232 - val_loss: 0.6321 - val_accuracy: 0.0573\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2290 - accuracy: 0.0196 - val_loss: 0.6422 - val_accuracy: 0.0370\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2317 - accuracy: 0.0348 - val_loss: 0.6543 - val_accuracy: 0.6631\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2198 - accuracy: 0.0734 - val_loss: 0.5668 - val_accuracy: 0.0131\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2092 - accuracy: 0.0133 - val_loss: 0.6696 - val_accuracy: 0.0203\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2153 - accuracy: 0.0253 - val_loss: 0.6429 - val_accuracy: 0.0370\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2552 - accuracy: 0.0314 - val_loss: 0.6732 - val_accuracy: 0.0084\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2700 - accuracy: 0.0447 - val_loss: 0.5906 - val_accuracy: 0.1565\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2599 - accuracy: 0.0532 - val_loss: 0.6749 - val_accuracy: 0.0406\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2477 - accuracy: 0.0306 - val_loss: 0.5999 - val_accuracy: 0.0215\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2480 - accuracy: 0.0401 - val_loss: 0.6019 - val_accuracy: 0.1123\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2315 - accuracy: 0.0614 - val_loss: 0.6933 - val_accuracy: 0.0335\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2293 - accuracy: 0.0403 - val_loss: 0.6203 - val_accuracy: 0.1470\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2192 - accuracy: 0.0272 - val_loss: 0.6162 - val_accuracy: 0.0108\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2236 - accuracy: 0.0433 - val_loss: 0.6813 - val_accuracy: 0.0729\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2241 - accuracy: 0.0582 - val_loss: 0.5937 - val_accuracy: 0.0191\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2219 - accuracy: 0.0568 - val_loss: 0.6392 - val_accuracy: 0.0119\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.2119 - accuracy: 0.0475 - val_loss: 0.7243 - val_accuracy: 0.0227\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2116 - accuracy: 0.0736 - val_loss: 0.6460 - val_accuracy: 0.0287\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2108 - accuracy: 0.0344 - val_loss: 0.6354 - val_accuracy: 0.0024\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2024 - accuracy: 0.0336 - val_loss: 0.6572 - val_accuracy: 0.0084\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.0466 - val_loss: 0.5977 - val_accuracy: 0.0239\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2011 - accuracy: 0.0200 - val_loss: 0.6797 - val_accuracy: 0.0167\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1928 - accuracy: 0.0373 - val_loss: 0.7377 - val_accuracy: 0.0227\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2082 - accuracy: 0.0559 - val_loss: 0.7433 - val_accuracy: 0.1087\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1982 - accuracy: 0.0502 - val_loss: 0.7012 - val_accuracy: 0.0382\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 2s 10ms/step - loss: 0.1877 - accuracy: 0.0293 - val_loss: 0.7425 - val_accuracy: 0.0119\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1895 - accuracy: 0.0070 - val_loss: 0.7807 - val_accuracy: 0.0311\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1956 - accuracy: 0.0268 - val_loss: 0.7470 - val_accuracy: 0.0131\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2120 - accuracy: 0.0127 - val_loss: 0.7130 - val_accuracy: 0.0167\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1868 - accuracy: 0.0255 - val_loss: 0.7036 - val_accuracy: 0.0072\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1829 - accuracy: 0.0276 - val_loss: 0.7501 - val_accuracy: 0.0179\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2215 - accuracy: 0.0762 - val_loss: 0.6694 - val_accuracy: 0.0562\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2128 - accuracy: 0.0148 - val_loss: 0.6426 - val_accuracy: 0.0323\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.2164 - accuracy: 0.0523 - val_loss: 0.6060 - val_accuracy: 0.0084\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 1s 10ms/step - loss: 0.1898 - accuracy: 0.0087 - val_loss: 0.6776 - val_accuracy: 0.0119\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1836 - accuracy: 0.0184 - val_loss: 0.8294 - val_accuracy: 0.0143\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1858 - accuracy: 0.0241 - val_loss: 0.7163 - val_accuracy: 0.0096\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.1840 - accuracy: 0.0209 - val_loss: 0.7359 - val_accuracy: 0.0167\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.1804 - accuracy: 0.0747 - val_loss: 0.7176 - val_accuracy: 0.0108\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.1789 - accuracy: 0.0490 - val_loss: 0.7677 - val_accuracy: 0.0155\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.1004 - val_loss: 0.8063 - val_accuracy: 0.0382\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.0791 - val_loss: 0.8171 - val_accuracy: 0.0072\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.1821 - accuracy: 0.0196 - val_loss: 0.7297 - val_accuracy: 0.0060\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.0918 - val_loss: 0.7695 - val_accuracy: 0.0323\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 0.1817 - accuracy: 0.0523 - val_loss: 0.8147 - val_accuracy: 0.0072\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.0167 - val_loss: 0.7191 - val_accuracy: 0.0119\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.0861 - val_loss: 0.7314 - val_accuracy: 0.0096\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 1s 5ms/step - loss: 0.1911 - accuracy: 0.0711 - val_loss: 0.7485 - val_accuracy: 0.0633\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.1814 - accuracy: 0.1517 - val_loss: 0.7981 - val_accuracy: 0.0394\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.1748 - accuracy: 0.0966 - val_loss: 0.8327 - val_accuracy: 0.0394\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 1s 7ms/step - loss: 0.1784 - accuracy: 0.0549 - val_loss: 0.7690 - val_accuracy: 0.0299\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.0694 - val_loss: 0.7775 - val_accuracy: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd5e395c8e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(final_input_dataset, final_target_dataset, epochs=100, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at some results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "path = ('/datasets/amelatur/data_slices/respiratory/baseline/30111809_final_predictions.npy')\n",
    "arr = np.load(path)\n",
    "plt.plot(arr[0])\n",
    "plt.plot(arr[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = arr[0]\n",
    "\n",
    "(predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = (np.zeros((predictions.shape))).astype(int)\n",
    "onset = 20\n",
    "start_event = max(0, onset - 8 * 2)\n",
    "target[start_event:onset]  =1\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('/datasets/amelatur/data_slices/respiratory/onset_index.csv', header=None, index_col=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(file[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"30111809_final_predictions.npy\"\n",
    "str = filename.split(\"_\")\n",
    "pt_id = str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30111809', 'final', 'predictions.npy']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(file[file[0] == 34995687][1].values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7649ba422fb855e8326f0b9af10e406050e974c9bb93677086f2c0ae9379c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
